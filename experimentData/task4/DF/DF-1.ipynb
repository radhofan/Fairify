{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fairify Artifact\n",
    "Artifact of the paper \"Fairify: Fairness Verification of Neural Networks\" from ICSE 2023.\n",
    "\n",
    "To access ChameleonCloud resources, you may need the account to log in to ChameleonCloud. You also need to have a project to allocate resources (e.g., node)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab1b39733f4b4266982e985d481c30ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Select Site', options=('CHI@TACC', 'CHI@UC', 'CHI@EVL', 'CHI@NCAR', 'CHI@…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "938968a983d940a8875ace367ade0cd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Select Project', options=('CHI-251412',), value='CHI-251412'), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from chi import context\n",
    "\n",
    "context.version = \"1.0\"\n",
    "\n",
    "context.choose_site(default=\"CHI@TACC\")\n",
    "context.choose_project()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check available hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There currently are 33 compute_cascadelake_r nodes ready to use\n"
     ]
    }
   ],
   "source": [
    "from chi import hardware\n",
    "\n",
    "node_type = \"compute_cascadelake_r\"\n",
    "available_nodes = hardware.get_nodes(node_type=node_type, filter_reserved=True)\n",
    "if available_nodes:\n",
    "    print(f\"There currently are {len(available_nodes)} {node_type} nodes ready to use\")\n",
    "else:\n",
    "    print(f\"All {node_type} nodes are in use! You could use next_free_timeslot to see how long you need to wait, or use the calendar.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reserve node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for lease to start... This can take up to 60 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fc535a8bcdb4d208fc1bcbac259b48f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value=''), IntProgress(value=0, bar_style='success')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lease radhofanazizi_gmail_com-power-management has reached status active\n"
     ]
    }
   ],
   "source": [
    "from chi import lease\n",
    "from datetime import timedelta\n",
    "import os\n",
    "\n",
    "my_lease = lease.Lease(f\"{os.getenv('USER')}-power-management\", duration=timedelta(hours=3))\n",
    "my_lease.add_node_reservation(nodes=[available_nodes[0]]) # or you could use node_type=node_type\n",
    "my_lease.add_fip_reservation(1) # include a floating ip\n",
    "my_lease.submit(idempotent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a server on the node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for server radhofanazizi_gmail_com-power-management's status to become ACTIVE. This typically takes 10 minutes, but can take up to 20 minutes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb00e467e6b14e97bd8061160a737347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value=''), IntProgress(value=0, bar_style='success')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server has moved to status ACTIVE\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style='border-collapse: collapse; width: 100%;'><tr style='background-color: #f2f2f2;'><th style='border: 1px solid #ddd; padding: 8px;'>Attribute</th><th style='border: 1px solid #ddd; padding: 8px;'>radhofanazizi_gmail_com-power-management</th></tr><tr><td style='border: 1px solid #ddd; padding: 8px;'>Id</td><td style='border: 1px solid #ddd; padding: 8px;'>d4dfe3f9-0b6f-4972-b1c0-66d047a9fe7c</td></tr><tr><td style='border: 1px solid #ddd; padding: 8px;'>Status</td><td style='border: 1px solid #ddd; padding: 8px;'>ACTIVE</td></tr><tr><td style='border: 1px solid #ddd; padding: 8px;'>Image Name</td><td style='border: 1px solid #ddd; padding: 8px;'>CC-Ubuntu22.04</td></tr><tr><td style='border: 1px solid #ddd; padding: 8px;'>Flavor Name</td><td style='border: 1px solid #ddd; padding: 8px;'>baremetal</td></tr><tr><td style='border: 1px solid #ddd; padding: 8px;'>Addresses</td><td style='border: 1px solid #ddd; padding: 8px;'><strong>sharednet1:</strong><br>&nbsp;&nbsp;IP: 10.52.3.93 (v4)<br>&nbsp;&nbsp;Type: fixed<br>&nbsp;&nbsp;MAC: bc:97:e1:78:f1:a0<br></td></tr><tr><td style='border: 1px solid #ddd; padding: 8px;'>Network Name</td><td style='border: 1px solid #ddd; padding: 8px;'>sharednet1</td></tr><tr><td style='border: 1px solid #ddd; padding: 8px;'>Created At</td><td style='border: 1px solid #ddd; padding: 8px;'>2025-05-18T07:38:32Z</td></tr><tr><td style='border: 1px solid #ddd; padding: 8px;'>Keypair</td><td style='border: 1px solid #ddd; padding: 8px;'>trovi-28d289c</td></tr><tr><td style='border: 1px solid #ddd; padding: 8px;'>Reservation Id</td><td style='border: 1px solid #ddd; padding: 8px;'>a381a41c-eec3-44c2-a657-8ad56aecff1e</td></tr><tr><td style='border: 1px solid #ddd; padding: 8px;'>Host Id</td><td style='border: 1px solid #ddd; padding: 8px;'>b281b13a05d4a4d342f673906de4005142c2819a049809e34ac97306</td></tr><tr><td style='border: 1px solid #ddd; padding: 8px;'>Host Status</td><td style='border: 1px solid #ddd; padding: 8px;'>None</td></tr><tr><td style='border: 1px solid #ddd; padding: 8px;'>Hypervisor Hostname</td><td style='border: 1px solid #ddd; padding: 8px;'>021d8369-10e4-429c-9df4-cc4eb86216ee</td></tr><tr><td style='border: 1px solid #ddd; padding: 8px;'>Is Locked</td><td style='border: 1px solid #ddd; padding: 8px;'>False</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from chi import server\n",
    "\n",
    "my_server = server.Server(\n",
    "    f\"{os.getenv('USER')}-power-management\",\n",
    "    reservation_id=my_lease.node_reservations[0][\"id\"],\n",
    "    image_name=\"CC-Ubuntu22.04\", # or use image_name\n",
    ")\n",
    "my_server.submit(idempotent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure networking on the node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking connectivity to 129.114.109.220 port 22.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15e04aa8b0384467ad8454106f5ea779",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value=''), IntProgress(value=0, bar_style='success')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful\n"
     ]
    }
   ],
   "source": [
    "fip = my_lease.get_reserved_floating_ips()[0]\n",
    "my_server.associate_floating_ip(fip)\n",
    "my_server.check_connectivity(host=fip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup nvidia drivers and cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_server.execute(\"\"\"\n",
    "sudo apt-get --purge remove -y '*cublas*' 'cuda*' 'nvidia-*' && \\\n",
    "sudo apt-get autoremove -y && \\\n",
    "sudo apt-get autoclean && \\\n",
    "sudo rm -rf /usr/local/cuda* && \\\n",
    "sudo apt update && \\\n",
    "sudo apt install -y nvidia-driver-470 && \\\n",
    "wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-keyring_1.0-1_all.deb && \\\n",
    "sudo dpkg -i cuda-keyring_1.0-1_all.deb && \\\n",
    "sudo apt update && \\\n",
    "sudo apt install -y cuda-toolkit-11-2\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart nvidia services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_server.execute(\"sudo modprobe -r nouveau\")\n",
    "my_server.execute(\"sudo rmmod nouveau 2>/dev/null || true\")\n",
    "my_server.execute(\"sudo update-initramfs -u\")\n",
    "my_server.execute(\"sudo modprobe nvidia\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifiy services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_server.execute(\"nvidia-smi\")\n",
    "my_server.execute(\"\"\"\n",
    "if [ -L /usr/local/bin/nvcc ]; then sudo rm /usr/local/bin/nvcc; fi && \\\n",
    "sudo ln -s /usr/local/cuda-11.2/bin/nvcc /usr/local/bin/nvcc\n",
    "\"\"\")\n",
    "my_server.execute(\"nvcc --version\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Fairify\n",
    "\n",
    "Now, we can finally run Fairify. First we need to clone the github repo first and then run the reprduce.sh script which contain the instructions from README.md\n",
    "packaged into a bash file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'Fairify'...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Result cmd='rm -rf Fairify && git clone https://github.com/radhofan/Fairify.git' exited=0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_server.execute(\"rm -rf Fairify && git clone https://github.com/radhofan/Fairify.git\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run dependencies and first experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: File or directory already exists: '/home/cc/miniconda'\n",
      "If you want to update an existing installation, use the -u option.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - conda-forge\n",
      " - defaults\n",
      "Platform: linux-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "Running `shell init`, which:\n",
      " - modifies RC file: \"/home/cc/.bashrc\"\n",
      " - generates config for root prefix: \u001b[1m\"/home/cc/miniconda\"\u001b[0m\n",
      " - sets mamba executable to: \u001b[1m\"/home/cc/miniconda/bin/mamba\"\u001b[0m\n",
      "The following has been added in your \"/home/cc/.bashrc\" file\n",
      "\n",
      "# >>> mamba initialize >>>\n",
      "# !! Contents within this block are managed by 'mamba shell init' !!\n",
      "export MAMBA_EXE='/home/cc/miniconda/bin/mamba';\n",
      "export MAMBA_ROOT_PREFIX='/home/cc/miniconda';\n",
      "__mamba_setup=\"$(\"$MAMBA_EXE\" shell hook --shell bash --root-prefix \"$MAMBA_ROOT_PREFIX\" 2> /dev/null)\"\n",
      "if [ $? -eq 0 ]; then\n",
      "    eval \"$__mamba_setup\"\n",
      "else\n",
      "    alias mamba=\"$MAMBA_EXE\"  # Fallback on help from mamba activate\n",
      "fi\n",
      "unset __mamba_setup\n",
      "# <<< mamba initialize <<<\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning  libmamba 'repo.anaconda.com', a commercial channel hosted by Anaconda.com, is used.\n",
      "    \n",
      "warning  libmamba Please make sure you understand Anaconda Terms of Services.\n",
      "    \n",
      "warning  libmamba See: https://legal.anaconda.com/policies/en/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Transaction\n",
      "\n",
      "  Prefix: /home/cc/miniconda/envs/fairify\n",
      "\n",
      "  Updating specs:\n",
      "\n",
      "   - python=3.9\n",
      "\n",
      "\n",
      "  Package               Version  Build           Channel         Size\n",
      "───────────────────────────────────────────────────────────────────────\n",
      "  Install:\n",
      "───────────────────────────────────────────────────────────────────────\n",
      "\n",
      "  + _libgcc_mutex           0.1  main            pkgs/main     Cached\n",
      "  + _openmp_mutex           5.1  1_gnu           pkgs/main     Cached\n",
      "  + ca-certificates   2025.2.25  h06a4308_0      pkgs/main     Cached\n",
      "  + ld_impl_linux-64       2.40  h12ee557_0      pkgs/main     Cached\n",
      "  + libffi                3.4.4  h6a678d5_1      pkgs/main     Cached\n",
      "  + libgcc-ng            11.2.0  h1234567_1      pkgs/main     Cached\n",
      "  + libgomp              11.2.0  h1234567_1      pkgs/main     Cached\n",
      "  + libstdcxx-ng         11.2.0  h1234567_1      pkgs/main     Cached\n",
      "  + ncurses                 6.4  h6a678d5_0      pkgs/main     Cached\n",
      "  + openssl              3.0.16  h5eee18b_0      pkgs/main     Cached\n",
      "  + pip                    25.1  pyhc872135_2    pkgs/main     Cached\n",
      "  + python               3.9.21  he870216_1      pkgs/main     Cached\n",
      "  + readline                8.2  h5eee18b_0      pkgs/main     Cached\n",
      "  + setuptools           78.1.1  py39h06a4308_0  pkgs/main     Cached\n",
      "  + sqlite               3.45.3  h5eee18b_0      pkgs/main     Cached\n",
      "  + tk                   8.6.14  h39e8969_0      pkgs/main     Cached\n",
      "  + tzdata                2025b  h04d1e81_0      pkgs/main     Cached\n",
      "  + wheel                0.45.1  py39h06a4308_0  pkgs/main     Cached\n",
      "  + xz                    5.6.4  h5eee18b_1      pkgs/main     Cached\n",
      "  + zlib                 1.2.13  h5eee18b_1      pkgs/main     Cached\n",
      "\n",
      "  Summary:\n",
      "\n",
      "  Install: 20 packages\n",
      "\n",
      "  Total download: 0 B\n",
      "\n",
      "───────────────────────────────────────────────────────────────────────\n",
      "\n",
      "\n",
      "\n",
      "Transaction starting\n",
      "Linking _libgcc_mutex-0.1-main\n",
      "Linking ld_impl_linux-64-2.40-h12ee557_0\n",
      "Linking libstdcxx-ng-11.2.0-h1234567_1\n",
      "Linking ca-certificates-2025.2.25-h06a4308_0\n",
      "Linking libgomp-11.2.0-h1234567_1\n",
      "Linking _openmp_mutex-5.1-1_gnu\n",
      "Linking libgcc-ng-11.2.0-h1234567_1\n",
      "Linking xz-5.6.4-h5eee18b_1\n",
      "Linking openssl-3.0.16-h5eee18b_0\n",
      "Linking libffi-3.4.4-h6a678d5_1\n",
      "Linking zlib-1.2.13-h5eee18b_1\n",
      "Linking ncurses-6.4-h6a678d5_0\n",
      "Linking tk-8.6.14-h39e8969_0\n",
      "Linking readline-8.2-h5eee18b_0\n",
      "Linking sqlite-3.45.3-h5eee18b_0\n",
      "Linking tzdata-2025b-h04d1e81_0\n",
      "Linking python-3.9.21-he870216_1\n",
      "Linking wheel-0.45.1-py39h06a4308_0\n",
      "Linking setuptools-78.1.1-py39h06a4308_0\n",
      "Linking pip-25.1-pyhc872135_2\n",
      "\n",
      "Transaction finished\n",
      "\n",
      "\n",
      "To activate this environment, use:\n",
      "\n",
      "    mamba activate fairify\n",
      "\n",
      "Or to execute a single command in this environment, use:\n",
      "\n",
      "    mamba run -n fairify mycommand\n",
      "\n",
      "Collecting z3-solver (from -r Fairify/requirements.txt (line 1))\n",
      "  Using cached z3_solver-4.15.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (602 bytes)\n",
      "Collecting tensorflow==2.5.0 (from -r Fairify/requirements.txt (line 2))\n",
      "  Using cached tensorflow-2.5.0-cp39-cp39-manylinux2010_x86_64.whl.metadata (2.8 kB)\n",
      "Collecting aif360 (from -r Fairify/requirements.txt (line 3))\n",
      "  Using cached aif360-0.6.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting numpy~=1.19.2 (from tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached numpy-1.19.5-cp39-cp39-manylinux2010_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting absl-py~=0.10 (from tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached absl_py-0.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting astunparse~=1.6.3 (from tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers~=1.12.0 (from tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached flatbuffers-1.12-py2.py3-none-any.whl.metadata (872 bytes)\n",
      "Collecting google-pasta~=0.2 (from tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py~=3.1.0 (from tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached h5py-3.1.0-cp39-cp39-manylinux1_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting keras-preprocessing~=1.1.2 (from tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opt-einsum~=3.3.0 (from tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting protobuf>=3.9.2 (from tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached protobuf-6.31.0-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Collecting six~=1.15.0 (from tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached six-1.15.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting termcolor~=1.1.0 (from tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached termcolor-1.1.0-py3-none-any.whl\n",
      "Collecting typing-extensions~=3.7.4 (from tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached typing_extensions-3.7.4.3-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: wheel~=0.35 in ./miniconda/envs/fairify/lib/python3.9/site-packages (from tensorflow==2.5.0->-r Fairify/requirements.txt (line 2)) (0.45.1)\n",
      "Collecting wrapt~=1.12.1 (from tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached wrapt-1.12.1-cp39-cp39-linux_x86_64.whl\n",
      "Collecting gast==0.4.0 (from tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting tensorboard~=2.5 (from tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting tensorflow-estimator<2.6.0,>=2.5.0rc0 (from tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached tensorflow_estimator-2.5.0-py2.py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting keras-nightly~=2.5.0.dev (from tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting grpcio~=1.34.0 (from tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached grpcio-1.34.1-cp39-cp39-manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "INFO: pip is looking at multiple versions of tensorboard to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tensorboard~=2.5 (from tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "  Using cached tensorboard-2.17.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "  Using cached tensorboard-2.17.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "  Using cached tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "  Using cached tensorboard-2.16.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "  Using cached tensorboard-2.16.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "  Using cached tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "INFO: pip is still looking at multiple versions of tensorboard to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached tensorboard-2.15.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "  Using cached tensorboard-2.15.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "  Using cached tensorboard-2.14.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "  Using cached tensorboard-2.14.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "  Using cached tensorboard-2.13.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached tensorboard-2.12.3-py3-none-any.whl.metadata (1.8 kB)\n",
      "  Using cached tensorboard-2.12.2-py3-none-any.whl.metadata (1.8 kB)\n",
      "  Using cached tensorboard-2.12.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "  Using cached tensorboard-2.12.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "  Using cached tensorboard-2.11.2-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard~=2.5->tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached google_auth-2.40.1-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard~=2.5->tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.5->tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached markdown-3.8-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting protobuf>=3.9.2 (from tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached protobuf-3.20.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (679 bytes)\n",
      "Collecting requests<3,>=2.21.0 (from tensorboard~=2.5->tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in ./miniconda/envs/fairify/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow==2.5.0->-r Fairify/requirements.txt (line 2)) (78.1.1)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard~=2.5->tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0 (from tensorboard~=2.5->tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl.metadata (873 bytes)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.5->tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached charset_normalizer-3.4.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached certifi-2025.4.26-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting scipy>=1.2.0 (from aif360->-r Fairify/requirements.txt (line 3))\n",
      "  Using cached scipy-1.13.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Collecting pandas>=0.24.0 (from aif360->-r Fairify/requirements.txt (line 3))\n",
      "  Using cached pandas-2.2.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Collecting scikit-learn>=1.0 (from aif360->-r Fairify/requirements.txt (line 3))\n",
      "  Using cached scikit_learn-1.6.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting matplotlib (from aif360->-r Fairify/requirements.txt (line 3))\n",
      "  Using cached matplotlib-3.9.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting importlib-metadata>=4.4 (from markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting zipp>=3.20 (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "INFO: pip is looking at multiple versions of pandas to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pandas>=0.24.0 (from aif360->-r Fairify/requirements.txt (line 3))\n",
      "  Using cached pandas-2.2.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "  Using cached pandas-2.2.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "  Using cached pandas-2.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "  Using cached pandas-2.1.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "  Using cached pandas-2.1.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "  Using cached pandas-2.1.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "  Using cached pandas-2.1.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "INFO: pip is still looking at multiple versions of pandas to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached pandas-2.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "  Using cached pandas-2.0.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting python-dateutil>=2.8.2 (from pandas>=0.24.0->aif360->-r Fairify/requirements.txt (line 3))\n",
      "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting pytz>=2020.1 (from pandas>=0.24.0->aif360->-r Fairify/requirements.txt (line 3))\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.1 (from pandas>=0.24.0->aif360->-r Fairify/requirements.txt (line 3))\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting pandas>=0.24.0 (from aif360->-r Fairify/requirements.txt (line 3))\n",
      "  Using cached pandas-2.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "  Using cached pandas-2.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "  Using cached pandas-2.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached pandas-1.5.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "  Using cached pandas-1.5.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "  Using cached pandas-1.5.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "  Using cached pandas-1.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "  Using cached pandas-1.4.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn>=1.0->aif360->-r Fairify/requirements.txt (line 3))\n",
      "  Using cached joblib-1.5.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn>=1.0->aif360->-r Fairify/requirements.txt (line 3))\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "INFO: pip is looking at multiple versions of scipy to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting scipy>=1.2.0 (from aif360->-r Fairify/requirements.txt (line 3))\n",
      "  Using cached scipy-1.13.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "  Using cached scipy-1.12.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "  Using cached scipy-1.11.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "  Using cached scipy-1.11.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "  Using cached scipy-1.11.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (59 kB)\n",
      "  Using cached scipy-1.11.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (59 kB)\n",
      "  Using cached scipy-1.10.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
      "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard~=2.5->tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached MarkupSafe-3.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib->aif360->-r Fairify/requirements.txt (line 3))\n",
      "  Using cached contourpy-1.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib->aif360->-r Fairify/requirements.txt (line 3))\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib->aif360->-r Fairify/requirements.txt (line 3))\n",
      "  Using cached fonttools-4.58.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (104 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib->aif360->-r Fairify/requirements.txt (line 3))\n",
      "  Using cached kiwisolver-1.4.7-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.3 kB)\n",
      "INFO: pip is looking at multiple versions of matplotlib to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting matplotlib (from aif360->-r Fairify/requirements.txt (line 3))\n",
      "  Using cached matplotlib-3.9.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "  Using cached matplotlib-3.9.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "  Using cached matplotlib-3.9.1.post1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "  Using cached matplotlib-3.9.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "  Using cached matplotlib-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "  Using cached matplotlib-3.8.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "  Using cached matplotlib-3.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "INFO: pip is still looking at multiple versions of matplotlib to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached matplotlib-3.8.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "  Using cached matplotlib-3.8.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "  Using cached matplotlib-3.7.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\n",
      "  Using cached matplotlib-3.7.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\n",
      "  Using cached matplotlib-3.7.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached matplotlib-3.7.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "  Using cached matplotlib-3.7.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "  Using cached matplotlib-3.7.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "  Using cached matplotlib-3.6.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting packaging>=20.0 (from matplotlib->aif360->-r Fairify/requirements.txt (line 3))\n",
      "  Using cached packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting pillow>=6.2.0 (from matplotlib->aif360->-r Fairify/requirements.txt (line 3))\n",
      "  Using cached pillow-11.2.1-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
      "Collecting pyparsing>=2.2.1 (from matplotlib->aif360->-r Fairify/requirements.txt (line 3))\n",
      "  Using cached pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "INFO: pip is looking at multiple versions of contourpy to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting contourpy>=1.0.1 (from matplotlib->aif360->-r Fairify/requirements.txt (line 3))\n",
      "  Using cached contourpy-1.2.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "  Using cached contourpy-1.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "  Using cached contourpy-1.1.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.9 kB)\n",
      "Using cached tensorflow-2.5.0-cp39-cp39-manylinux2010_x86_64.whl (454.4 MB)\n",
      "Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Using cached absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Using cached grpcio-1.34.1-cp39-cp39-manylinux2014_x86_64.whl (4.0 MB)\n",
      "Using cached h5py-3.1.0-cp39-cp39-manylinux1_x86_64.whl (4.4 MB)\n",
      "Using cached keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)\n",
      "Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Using cached numpy-1.19.5-cp39-cp39-manylinux2010_x86_64.whl (14.9 MB)\n",
      "Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Using cached six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Using cached tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
      "Using cached google_auth-2.40.1-py2.py3-none-any.whl (216 kB)\n",
      "Using cached cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Using cached protobuf-3.20.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Using cached tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "Using cached tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n",
      "Using cached typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Using cached urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
      "Using cached z3_solver-4.15.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.5 MB)\n",
      "Using cached aif360-0.6.1-py3-none-any.whl (259 kB)\n",
      "Using cached certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
      "Using cached markdown-3.8-py3-none-any.whl (106 kB)\n",
      "Using cached importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\n",
      "Using cached pandas-1.4.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
      "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Using cached pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Using cached scikit_learn-1.6.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
      "Using cached joblib-1.5.0-py3-none-any.whl (307 kB)\n",
      "Using cached scipy-1.10.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
      "Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20 kB)\n",
      "Using cached zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
      "Using cached matplotlib-3.6.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.8 MB)\n",
      "Using cached contourpy-1.1.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.58.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "Using cached kiwisolver-1.4.7-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "Using cached packaging-25.0-py3-none-any.whl (66 kB)\n",
      "Using cached pillow-11.2.1-cp39-cp39-manylinux_2_28_x86_64.whl (4.6 MB)\n",
      "Using cached pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Installing collected packages: z3-solver, wrapt, typing-extensions, termcolor, tensorflow-estimator, tensorboard-plugin-wit, pytz, keras-nightly, flatbuffers, zipp, urllib3, threadpoolctl, tensorboard-data-server, six, pyparsing, pyasn1, protobuf, pillow, packaging, oauthlib, numpy, MarkupSafe, kiwisolver, joblib, idna, gast, fonttools, cycler, charset-normalizer, certifi, cachetools, werkzeug, scipy, rsa, requests, python-dateutil, pyasn1-modules, opt-einsum, keras-preprocessing, importlib-metadata, h5py, grpcio, google-pasta, contourpy, astunparse, absl-py, scikit-learn, requests-oauthlib, pandas, matplotlib, markdown, google-auth, google-auth-oauthlib, aif360, tensorboard, tensorflow\n",
      "\n",
      "Successfully installed MarkupSafe-3.0.2 absl-py-0.15.0 aif360-0.6.1 astunparse-1.6.3 cachetools-5.5.2 certifi-2025.4.26 charset-normalizer-3.4.2 contourpy-1.1.1 cycler-0.12.1 flatbuffers-1.12 fonttools-4.58.0 gast-0.4.0 google-auth-2.40.1 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.34.1 h5py-3.1.0 idna-3.10 importlib-metadata-8.7.0 joblib-1.5.0 keras-nightly-2.5.0.dev2021032900 keras-preprocessing-1.1.2 kiwisolver-1.4.7 markdown-3.8 matplotlib-3.6.3 numpy-1.19.5 oauthlib-3.2.2 opt-einsum-3.3.0 packaging-25.0 pandas-1.4.4 pillow-11.2.1 protobuf-3.20.3 pyasn1-0.6.1 pyasn1-modules-0.4.2 pyparsing-3.2.3 python-dateutil-2.9.0.post0 pytz-2025.2 requests-2.32.3 requests-oauthlib-2.0.0 rsa-4.9.1 scikit-learn-1.6.1 scipy-1.10.1 six-1.15.0 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.5.0 tensorflow-estimator-2.5.0 termcolor-1.1.0 threadpoolctl-3.6.0 typing-extensions-3.7.4.3 urllib3-2.4.0 werkzeug-3.1.3 wrapt-1.12.1 z3-solver-4.15.0.0 zipp-3.21.0\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.67.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "csvtool is already the newest version (2.4-1build3).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.\n",
      "Started running verification for Fairify/src/DF/Verify-DF.py models.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-18 08:44:45.707068: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2025-05-18 08:44:45.707089: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "WARNING:root:No module named 'fairlearn': ExponentiatedGradientReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'inFairness': SenSeI and SenSR will be unavailable. To install, run:\n",
      "pip install 'aif360[inFairness]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading default...\n",
      "All columns after encoding and dropping: ['LIMIT_BAL', 'AGE', 'PAY_1', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6', 'default.payment.next.month', 'SEX_2', 'EDUCATION_1', 'EDUCATION_2', 'EDUCATION_3', 'EDUCATION_4', 'EDUCATION_5', 'EDUCATION_6', 'MARRIAGE_1', 'MARRIAGE_2', 'MARRIAGE_3']\n",
      "after tiemouts and dir\n",
      "before partition\n",
      "Number of partitions:  6\n",
      "p_list contents: [{'PAY_1': [0.0, 1.0], 'PAY_2': [0.0, 1.0], 'PAY_3': [0.0, 1.0], 'PAY_4': [0.0, 1.0], 'PAY_5': [0.0, 1.0], 'PAY_6': [0.0, 1.0], 'SEX_2': [0.0, 1.0], 'EDUCATION_1': [0.0, 1.0], 'EDUCATION_2': [0.0, 1.0], 'EDUCATION_3': [0.0, 1.0], 'EDUCATION_4': [0.0, 1.0], 'EDUCATION_5': [0.0, 1.0], 'EDUCATION_6': [0.0, 1.0], 'MARRIAGE_1': [0.0, 1.0], 'MARRIAGE_2': [0.0, 1.0], 'MARRIAGE_3': [0.0, 1.0], 'LIMIT_BAL': [10000.0, 1000000.0], 'BILL_AMT1': [-165580.0, 964511.0], 'BILL_AMT2': [-69777.0, 983931.0], 'BILL_AMT3': [-157264.0, 1664089.0], 'BILL_AMT4': [-170000.0, 891586.0], 'BILL_AMT5': [-81334.0, 927171.0], 'BILL_AMT6': [-339603.0, 961664.0], 'PAY_AMT1': [0.0, 873552.0], 'PAY_AMT2': [0.0, 1684259.0], 'PAY_AMT3': [0.0, 896040.0], 'PAY_AMT4': [0.0, 621000.0], 'PAY_AMT5': [0.0, 426529.0], 'PAY_AMT6': [0.0, 528666.0], 'AGE': [41, 50]}, {'PAY_1': [0.0, 1.0], 'PAY_2': [0.0, 1.0], 'PAY_3': [0.0, 1.0], 'PAY_4': [0.0, 1.0], 'PAY_5': [0.0, 1.0], 'PAY_6': [0.0, 1.0], 'SEX_2': [0.0, 1.0], 'EDUCATION_1': [0.0, 1.0], 'EDUCATION_2': [0.0, 1.0], 'EDUCATION_3': [0.0, 1.0], 'EDUCATION_4': [0.0, 1.0], 'EDUCATION_5': [0.0, 1.0], 'EDUCATION_6': [0.0, 1.0], 'MARRIAGE_1': [0.0, 1.0], 'MARRIAGE_2': [0.0, 1.0], 'MARRIAGE_3': [0.0, 1.0], 'LIMIT_BAL': [10000.0, 1000000.0], 'BILL_AMT1': [-165580.0, 964511.0], 'BILL_AMT2': [-69777.0, 983931.0], 'BILL_AMT3': [-157264.0, 1664089.0], 'BILL_AMT4': [-170000.0, 891586.0], 'BILL_AMT5': [-81334.0, 927171.0], 'BILL_AMT6': [-339603.0, 961664.0], 'PAY_AMT1': [0.0, 873552.0], 'PAY_AMT2': [0.0, 1684259.0], 'PAY_AMT3': [0.0, 896040.0], 'PAY_AMT4': [0.0, 621000.0], 'PAY_AMT5': [0.0, 426529.0], 'PAY_AMT6': [0.0, 528666.0], 'AGE': [51, 60]}, {'PAY_1': [0.0, 1.0], 'PAY_2': [0.0, 1.0], 'PAY_3': [0.0, 1.0], 'PAY_4': [0.0, 1.0], 'PAY_5': [0.0, 1.0], 'PAY_6': [0.0, 1.0], 'SEX_2': [0.0, 1.0], 'EDUCATION_1': [0.0, 1.0], 'EDUCATION_2': [0.0, 1.0], 'EDUCATION_3': [0.0, 1.0], 'EDUCATION_4': [0.0, 1.0], 'EDUCATION_5': [0.0, 1.0], 'EDUCATION_6"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Models:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "': [0.0, 1.0], 'MARRIAGE_1': [0.0, 1.0], 'MARRIAGE_2': [0.0, 1.0], 'MARRIAGE_3': [0.0, 1.0], 'LIMIT_BAL': [10000.0, 1000000.0], 'BILL_AMT1': [-165580.0, 964511.0], 'BILL_AMT2': [-69777.0, 983931.0], 'BILL_AMT3': [-157264.0, 1664089.0], 'BILL_AMT4': [-170000.0, 891586.0], 'BILL_AMT5': [-81334.0, 927171.0], 'BILL_AMT6': [-339603.0, 961664.0], 'PAY_AMT1': [0.0, 873552.0], 'PAY_AMT2': [0.0, 1684259.0], 'PAY_AMT3': [0.0, 896040.0], 'PAY_AMT4': [0.0, 621000.0], 'PAY_AMT5': [0.0, 426529.0], 'PAY_AMT6': [0.0, 528666.0], 'AGE': [71, 79]}, {'PAY_1': [0.0, 1.0], 'PAY_2': [0.0, 1.0], 'PAY_3': [0.0, 1.0], 'PAY_4': [0.0, 1.0], 'PAY_5': [0.0, 1.0], 'PAY_6': [0.0, 1.0], 'SEX_2': [0.0, 1.0], 'EDUCATION_1': [0.0, 1.0], 'EDUCATION_2': [0.0, 1.0], 'EDUCATION_3': [0.0, 1.0], 'EDUCATION_4': [0.0, 1.0], 'EDUCATION_5': [0.0, 1.0], 'EDUCATION_6': [0.0, 1.0], 'MARRIAGE_1': [0.0, 1.0], 'MARRIAGE_2': [0.0, 1.0], 'MARRIAGE_3': [0.0, 1.0], 'LIMIT_BAL': [10000.0, 1000000.0], 'BILL_AMT1': [-165580.0, 964511.0], 'BILL_AMT2': [-69777.0, 983931.0], 'BILL_AMT3': [-157264.0, 1664089.0], 'BILL_AMT4': [-170000.0, 891586.0], 'BILL_AMT5': [-81334.0, 927171.0], 'BILL_AMT6': [-339603.0, 961664.0], 'PAY_AMT1': [0.0, 873552.0], 'PAY_AMT2': [0.0, 1684259.0], 'PAY_AMT3': [0.0, 896040.0], 'PAY_AMT4': [0.0, 621000.0], 'PAY_AMT5': [0.0, 426529.0], 'PAY_AMT6': [0.0, 528666.0], 'AGE': [61, 70]}, {'PAY_1': [0.0, 1.0], 'PAY_2': [0.0, 1.0], 'PAY_3': [0.0, 1.0], 'PAY_4': [0.0, 1.0], 'PAY_5': [0.0, 1.0], 'PAY_6': [0.0, 1.0], 'SEX_2': [0.0, 1.0], 'EDUCATION_1': [0.0, 1.0], 'EDUCATION_2': [0.0, 1.0], 'EDUCATION_3': [0.0, 1.0], 'EDUCATION_4': [0.0, 1.0], 'EDUCATION_5': [0.0, 1.0], 'EDUCATION_6': [0.0, 1.0], 'MARRIAGE_1': [0.0, 1.0], 'MARRIAGE_2': [0.0, 1.0], 'MARRIAGE_3': [0.0, 1.0], 'LIMIT_BAL': [10000.0, 1000000.0], 'BILL_AMT1': [-165580.0, 964511.0], 'BILL_AMT2': [-69777.0, 983931.0], 'BILL_AMT3': [-157264.0, 1664089.0], 'BILL_AMT4': [-170000.0, 891586.0], 'BILL_AMT5': [-81334.0, 927171.0], 'BILL_AMT6': [-339603.0, 961664.0], 'PAY_AMT1': [0.0, 873552.0], 'PAY_AMT2': [0.0, 1684259.0], 'PAY_AMT3': [0.0, 896040.0], 'PAY_AMT4': [0.0, 621000.0], 'PAY_AMT5': [0.0, 426529.0], 'PAY_AMT6': [0.0, 528666.0], 'AGE': [21, 30]}, {'PAY_1': [0.0, 1.0], 'PAY_2': [0.0, 1.0], 'PAY_3': [0.0, 1.0], 'PAY_4': [0.0, 1.0], 'PAY_5': [0.0, 1.0], 'PAY_6': [0.0, 1.0], 'SEX_2': [0.0, 1.0], 'EDUCATION_1': [0.0, 1.0], 'EDUCATION_2': [0.0, 1.0], 'EDUCATION_3': [0.0, 1.0], 'EDUCATION_4': [0.0, 1.0], 'EDUCATION_5': [0.0, 1.0], 'EDUCATION_6': [0.0, 1.0], 'MARRIAGE_1': [0.0, 1.0], 'MARRIAGE_2': [0.0, 1.0], 'MARRIAGE_3': [0.0, 1.0], 'LIMIT_BAL': [10000.0, 1000000.0], 'BILL_AMT1': [-165580.0, 964511.0], 'BILL_AMT2': [-69777.0, 983931.0], 'BILL_AMT3': [-157264.0, 1664089.0], 'BILL_AMT4': [-170000.0, 891586.0], 'BILL_AMT5': [-81334.0, 927171.0], 'BILL_AMT6': [-339603.0, 961664.0], 'PAY_AMT1': [0.0, 873552.0], 'PAY_AMT2': [0.0, 1684259.0], 'PAY_AMT3': [0.0, 896040.0], 'PAY_AMT4': [0.0, 621000.0], 'PAY_AMT5': [0.0, 426529.0], 'PAY_AMT6': [0.0, 528666.0], 'AGE': [31, 40]}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-18 08:44:48.549309: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2025-05-18 08:44:48.549333: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2025-05-18 08:44:48.549348: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (radhofanazizi-gmail-com-power-management): /proc/driver/nvidia/version does not exist\n",
      "2025-05-18 08:44:48.549538: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================  STARTING MODEL DF-1.h5\n",
      "###################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Partitions:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Processing Partitions:  17%|█▋        | 1/6 [03:21<16:48, 201.75s/it]\u001b[A\n",
      "Processing Partitions:  33%|███▎      | 2/6 [06:43<13:27, 201.93s/it]\u001b[A\n",
      "Processing Partitions:  50%|█████     | 3/6 [10:06<10:06, 202.22s/it]\u001b[A\n",
      "Processing Partitions:  67%|██████▋   | 4/6 [13:28<06:44, 202.07s/it]\u001b[A\n",
      "Processing Partitions:  83%|████████▎ | 5/6 [16:50<03:22, 202.26s/it]\u001b[A\n",
      "Processing Partitions: 100%|██████████| 6/6 [20:13<00:00, 202.27s/it]\u001b[A\n",
      "Processing Models:  20%|██        | 1/5 [20:13<1:20:55, 1213.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTERVAL BASED PRUNING\n",
      "SINGULAR VERIFICATION\n",
      "Pruning done!\n",
      "Expected input size: 30, Actual input size: 30\n",
      "Expected input size: 30, Actual input size: 30\n",
      "Verifying ...\n",
      "unknown\n",
      "Pruning done!\n",
      "0.0 % HEURISTIC PRUNING\n",
      "0.0 % TOTAL PRUNING\n",
      "Expected input size: 30, Actual input size: 30\n",
      "Expected input size: 30, Actual input size: 30\n",
      "Verifying ...\n",
      "unknown\n",
      "V time:  100.064\n",
      "******************\n",
      "21th column\n",
      "0       0.0\n",
      "1       1.0\n",
      "2       1.0\n",
      "3       0.0\n",
      "4       1.0\n",
      "       ... \n",
      "4495    1.0\n",
      "4496    0.0\n",
      "4497    1.0\n",
      "4498    1.0\n",
      "4499    0.0\n",
      "Name: 20, Length: 4500, dtype: float64\n",
      "y_true\n",
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       1\n",
      "       ..\n",
      "4495    0\n",
      "4496    1\n",
      "4497    0\n",
      "4498    1\n",
      "4499    0\n",
      "Length: 4500, dtype: int64\n",
      "True: 1003 | False: 3497\n",
      "y_pred\n",
      "0        True\n",
      "1        True\n",
      "2        True\n",
      "3       False\n",
      "4        True\n",
      "        ...  \n",
      "4495    False\n",
      "4496     True\n",
      "4497    False\n",
      "4498     True\n",
      "4499    False\n",
      "Length: 4500, dtype: bool\n",
      "True: 1648 | False: 2852\n",
      "prot_attr\n",
      "0       0.0\n",
      "1       1.0\n",
      "2       1.0\n",
      "3       0.0\n",
      "4       1.0\n",
      "       ... \n",
      "4495    1.0\n",
      "4496    0.0\n",
      "4497    1.0\n",
      "4498    1.0\n",
      "4499    0.0\n",
      "Length: 4500, dtype: float64\n",
      "INTERVAL BASED PRUNING\n",
      "SINGULAR VERIFICATION\n",
      "Pruning done!\n",
      "Expected input size: 30, Actual input size: 30\n",
      "Expected input size: 30, Actual input size: 30\n",
      "Verifying ...\n",
      "unknown\n",
      "Pruning done!\n",
      "0.0 % HEURISTIC PRUNING\n",
      "0.0 % TOTAL PRUNING\n",
      "Expected input size: 30, Actual input size: 30\n",
      "Expected input size: 30, Actual input size: 30\n",
      "Verifying ...\n",
      "unknown\n",
      "V time:  100.023\n",
      "******************\n",
      "21th column\n",
      "0       0.0\n",
      "1       1.0\n",
      "2       1.0\n",
      "3       0.0\n",
      "4       1.0\n",
      "       ... \n",
      "4495    1.0\n",
      "4496    0.0\n",
      "4497    1.0\n",
      "4498    1.0\n",
      "4499    0.0\n",
      "Name: 20, Length: 4500, dtype: float64\n",
      "y_true\n",
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       1\n",
      "       ..\n",
      "4495    0\n",
      "4496    1\n",
      "4497    0\n",
      "4498    1\n",
      "4499    0\n",
      "Length: 4500, dtype: int64\n",
      "True: 1003 | False: 3497\n",
      "y_pred\n",
      "0        True\n",
      "1        True\n",
      "2        True\n",
      "3       False\n",
      "4        True\n",
      "        ...  \n",
      "4495    False\n",
      "4496     True\n",
      "4497    False\n",
      "4498     T"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/cc/Fairify/src/DF/Verify-DF.py\", line 144, in <module>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rue\n",
      "4499    False\n",
      "Length: 4500, dtype: bool\n",
      "True: 1648 | False: 2852\n",
      "prot_attr\n",
      "0       0.0\n",
      "1       1.0\n",
      "2       1.0\n",
      "3       0.0\n",
      "4       1.0\n",
      "       ... \n",
      "4495    1.0\n",
      "4496    0.0\n",
      "4497    1.0\n",
      "4498    1.0\n",
      "4499    0.0\n",
      "Length: 4500, dtype: float64\n",
      "INTERVAL BASED PRUNING\n",
      "SINGULAR VERIFICATION\n",
      "Pruning done!\n",
      "Expected input size: 30, Actual input size: 30\n",
      "Expected input size: 30, Actual input size: 30\n",
      "Verifying ...\n",
      "unknown\n",
      "Pruning done!\n",
      "0.0 % HEURISTIC PRUNING\n",
      "0.0 % TOTAL PRUNING\n",
      "Expected input size: 30, Actual input size: 30\n",
      "Expected input size: 30, Actual input size: 30\n",
      "Verifying ...\n",
      "unknown\n",
      "V time:  100.148\n",
      "******************\n",
      "21th column\n",
      "0       0.0\n",
      "1       1.0\n",
      "2       1.0\n",
      "3       0.0\n",
      "4       1.0\n",
      "       ... \n",
      "4495    1.0\n",
      "4496    0.0\n",
      "4497    1.0\n",
      "4498    1.0\n",
      "4499    0.0\n",
      "Name: 20, Length: 4500, dtype: float64\n",
      "y_true\n",
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       1\n",
      "       ..\n",
      "4495    0\n",
      "4496    1\n",
      "4497    0\n",
      "4498    1\n",
      "4499    0\n",
      "Length: 4500, dtype: int64\n",
      "True: 1003 | False: 3497\n",
      "y_pred\n",
      "0        True\n",
      "1 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    mod = import_module(model_funcs)\n",
      "  File \"/home/cc/miniconda/envs/fairify/lib/python3.9/importlib/__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1030, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 1007, in _find_and_load\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       True\n",
      "2        True\n",
      "3       False\n",
      "4        True\n",
      "        ...  \n",
      "4495    False\n",
      "4496     True\n",
      "4497    False\n",
      "4498     True\n",
      "4499    False\n",
      "Length: 4500, dtype: bool\n",
      "True: 1648 | False: 2852\n",
      "prot_attr\n",
      "0       0.0\n",
      "1       1.0\n",
      "2       1.0\n",
      "3       0.0\n",
      "4       1.0\n",
      "       ... \n",
      "4495    1.0\n",
      "4496    0.0\n",
      "4497    1.0\n",
      "4498    1.0\n",
      "4499    0.0\n",
      "Length: 4500, dtype: float64\n",
      "INTERVAL BASED PRUNING\n",
      "SINGULAR VERIFICATION\n",
      "Pruning done!\n",
      "Expected input size: 30, Actual input size: 30\n",
      "Expected input size: 30, Actual input size: 30\n",
      "Verifying ...\n",
      "unknown\n",
      "Pruning done!\n",
      "0.0 % HEURISTIC PRUNING\n",
      "0.0 % TOTAL PRUNING\n",
      "Expected input size: 30, Actual input size: 30\n",
      "Expected input size: 30, Actual input size: 30\n",
      "Verifying ...\n",
      "unknown\n",
      "V time:  100.006\n",
      "******************\n",
      "21th column\n",
      "0       0.0\n",
      "1       1.0\n",
      "2       1.0\n",
      "3       0.0\n",
      "4       1.0\n",
      "       ... \n",
      "4495    1.0\n",
      "4496    0.0\n",
      "4497    1.0\n",
      "4498    1.0\n",
      "4499    0.0\n",
      "Name: 20, Length: 4500, dtype: float64\n",
      "y_true\n",
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       1\n",
      "       ..\n",
      "4495    0\n",
      "4496    1\n",
      "4497    0\n",
      "4498    1\n",
      "4499    0\n",
      "Length: 4500, dtype: int64\n",
      "True: 1003 | False: 3497\n",
      "y_pred\n",
      "0        True\n",
      "1        True\n",
      "2        True\n",
      "3       False\n",
      "4        True\n",
      "        ...  \n",
      "4495    False\n",
      "4496     True\n",
      "4497    False\n",
      "4498     True\n",
      "4499    False\n",
      "Length: 4500, dtype: bool\n",
      "True: 1648 | False: 2852\n",
      "prot_attr\n",
      "0       0.0\n",
      "1       1.0\n",
      "2       1.0\n",
      "3       0.0\n",
      "4       1.0\n",
      "       ... \n",
      "4495    1.0\n",
      "4496    0.0\n",
      "4497    1.0\n",
      "4498    1.0\n",
      "4499    0.0\n",
      "Length: 4500, dtype: float64\n",
      "INTERVAL BASED PRUNING\n",
      "SINGULAR VERIFICATION\n",
      "Pruning done!\n",
      "Expected input size: 30, Actual input size: 30\n",
      "Expected input size: 30, Actual input size: 30\n",
      "Verifying ...\n",
      "unknown\n",
      "Pruning done!\n",
      "0.0 % HEURISTIC PRUNING\n",
      "0.0 % TOTAL PRUNING\n",
      "Expected input size: 30, Actual input size: 30\n",
      "Expected input size: 30, Actual input size: 30\n",
      "Verifying ...\n",
      "unknown\n",
      "V time:  100.862\n",
      "******************\n",
      "21th column\n",
      "0       0.0\n",
      "1       1.0\n",
      "2       1.0\n",
      "3       0.0\n",
      "4       1.0\n",
      "       ... \n",
      "4495    1.0\n",
      "4496    0.0\n",
      "4497    1.0\n",
      "4498    1.0\n",
      "449"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"<frozen importlib._bootstrap>\", line 984, in _find_and_load_unlocked\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9    0.0\n",
      "Name: 20, Length: 4500, dtype: float64\n",
      "y_true\n",
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       1\n",
      "       ..\n",
      "4495    0\n",
      "4496    1\n",
      "4497    0\n",
      "4498    1\n",
      "4499    0\n",
      "Length: 4500, dtype: int64\n",
      "True: 1003 | False: 3497\n",
      "y_pred\n",
      "0        True\n",
      "1        True\n",
      "2        True\n",
      "3       False\n",
      "4        True\n",
      "        ...  \n",
      "4495    False\n",
      "4496     True\n",
      "4497    False\n",
      "4498     True\n",
      "4499    False\n",
      "Length: 4500, dtype: bool\n",
      "True: 1648 | False: 2852\n",
      "prot_attr\n",
      "0       0.0\n",
      "1       1.0\n",
      "2       1.0\n",
      "3       0.0\n",
      "4       1.0\n",
      "       ... \n",
      "4495    1.0\n",
      "4496    0.0\n",
      "4497    1.0\n",
      "4498    1.0\n",
      "4499    0.0\n",
      "Length: 4500, dtype: float64\n",
      "INTERVAL BASED PRUNING\n",
      "SINGULAR VERIFICATION\n",
      "Pruning done!\n",
      "Expected input size: 30, Actual input size: 30\n",
      "Expected input size: 30, Actual input size: 30\n",
      "Verifying ...\n",
      "unknown\n",
      "Pruning done!\n",
      "0.0 % HEURISTIC PRUNING\n",
      "0.0 % TOTAL PRUNING\n",
      "Expected input size: 30, Actual input size: 30\n",
      "Expected input size: 30, Actual input size: 30\n",
      "Verifying ...\n",
      "unknown\n",
      "V time:  100.97\n",
      "******************\n",
      "21th column\n",
      "0       0.0\n",
      "1       1.0\n",
      "2       1.0\n",
      "3       0.0\n",
      "4       1.0\n",
      "       ... \n",
      "4495    1.0\n",
      "4496    0.0\n",
      "4497    1.0\n",
      "4498    1.0\n",
      "4499    0.0\n",
      "Name: 20, Length: 4500, dtype: float64\n",
      "y_true\n",
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       1\n",
      "       ..\n",
      "4495    0\n",
      "4496    1\n",
      "4497    0\n",
      "4498    1\n",
      "4499    0\n",
      "Length: 4500, dtype: int64\n",
      "True: 1003 | False: 3497\n",
      "y_pred\n",
      "0        True\n",
      "1        True\n",
      "2        True\n",
      "3       False\n",
      "4        True\n",
      "        ...  \n",
      "4495    False\n",
      "4496     True\n",
      "4497    False\n",
      "4498     True\n",
      "4499    False\n",
      "Length: 4500, dtype: bool\n",
      "True: 1648 | False: 2852\n",
      "prot_attr\n",
      "0       0.0\n",
      "1       1.0\n",
      "2       1.0\n",
      "3       0.0\n",
      "4       1.0\n",
      "       ... \n",
      "4495    1.0\n",
      "4496    0.0\n",
      "4497    1.0\n",
      "4498    1.0\n",
      "4499    0.0\n",
      "Length: 4500, dtype: float64\n",
      "==================  STARTING MODEL DF-4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ModuleNotFoundError: No module named 'utils.DF-4-Model-Functions'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Result cmd='bash Fairify/reproduce-experiment.sh' exited=0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_server.execute(\"chmod +x Fairify/reproduce-experiment.sh\")\n",
    "my_server.execute(\"bash Fairify/reproduce-experiment.sh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results for first experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partition_ID Verification SAT_count UNSAT_count UNK_count h_attempt h_success B_compression S_compression ST_compression H_compression T_compression SV-time S-time HV-Time H-Time Total-Time C-check V-accurate Original-acc Pruned-acc Acc-dec C1 C2\n",
      "1            unknown      0         0           1         1         0         0.0           0.0           0.0            0.0           0.0           100.014 100.61 100.064 100.34 200.95     0       0          0.6091       1.0        -          \n",
      "2            unknown      0         0           2         1         0         0.0           0.0           0.0            0.0           0.0           100.295 100.94 100.023 100.29 201.23     0       0          0.6091       1.0        -          \n",
      "3            unknown      0         0           3         1         0         0.0           0.0           0.0            0.0           0.0           100.774 101.36 100.148 100.42 201.78     0       0          0.6091       1.0        -          \n",
      "4            unknown      0         0           4         1         0         0.0           0.0           0.0            0.0           0.0           100.143 100.77 100.006 100.28 201.05     0       0          0.6091       1.0        -          \n",
      "5            unknown      0         0           5         1         0         0.0           0.0           0.0            0.0           0.0           100.053 100.67 100.862 101.13 201.81     0       0          0.6091       1.0        -          \n",
      "6            unknown      0         0           6         1         0         0.0           0.0           0.0            0.0           0.0           100.099 100.74 100.97  101.24 201.99     0       0          0.6091       1.0        -          \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Result cmd='csvtool readable Fairify/src/DF/DF-1.csv | less -S' exited=0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_server.execute(\"csvtool readable Fairify/src/DF/DF-1.csv | less -S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partition ID Original Accuracy  Original F1 Score   Pruned Accuracy Pruned F1 DI                 SPD                  EOD                AOD                  ERD                  CNT          TI\n",
      "1            0.6091111111111112 0.33647680120709167 1.0             1.0       1.0312860436654625 0.011315487014541603 0.0086764897215717 0.008923965698996894 0.009861184718996219 [0.91062222] 0.18992487920379048\n",
      "2            0.6091111111111112 0.33647680120709167 1.0             1.0       1.0312860436654625 0.011315487014541603 0.0086764897215717 0.008923965698996894 0.009861184718996219 [0.91062222] 0.18992487920379048\n",
      "3            0.6091111111111112 0.33647680120709167 1.0             1.0       1.0312860436654625 0.011315487014541603 0.0086764897215717 0.008923965698996894 0.009861184718996219 [0.91062222] 0.18992487920379048\n",
      "4            0.6091111111111112 0.33647680120709167 1.0             1.0       1.0312860436654625 0.011315487014541603 0.0086764897215717 0.008923965698996894 0.009861184718996219 [0.91062222] 0.18992487920379048\n",
      "5            0.6091111111111112 0.33647680120709167 1.0             1.0       1.0312860436654625 0.011315487014541603 0.0086764897215717 0.008923965698996894 0.009861184718996219 [0.91062222] 0.18992487920379048\n",
      "6            0.6091111111111112 0.33647680120709167 1.0             1.0       1.0312860436654625 0.011315487014541603 0.0086764897215717 0.008923965698996894 0.009861184718996219 [0.91062222] 0.18992487920379048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Result cmd='csvtool readable Fairify/src/DF/synthetic-default-predicted-DF-1-metrics.csv | less -S' exited=0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_server.execute(\"csvtool readable Fairify/src/DF/synthetic-default-predicted-DF-1-metrics.csv | less -S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
