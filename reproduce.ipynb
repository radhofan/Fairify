{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fairify Artifact\n",
    "Artifact of the paper \"Fairify: Fairness Verification of Neural Networks\" from ICSE 2023.\n",
    "\n",
    "To access ChameleonCloud resources, you may need the account to log in to ChameleonCloud. You also need to have a project to allocate resources (e.g., node)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from chi import context\n",
    "\n",
    "context.version = \"1.0\"\n",
    "\n",
    "context.choose_site(default=\"CHI@TACC\")\n",
    "context.choose_project()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check available hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from chi import hardware\n",
    "\n",
    "node_type = \"compute_cascadelake_r\"\n",
    "available_nodes = hardware.get_nodes(node_type=node_type, filter_reserved=True)\n",
    "if available_nodes:\n",
    "    print(f\"There currently are {len(available_nodes)} {node_type} nodes ready to use\")\n",
    "else:\n",
    "    print(f\"All {node_type} nodes are in use! You could use next_free_timeslot to see how long you need to wait, or use the calendar.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reserve node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for lease to start... This can take up to 60 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bac51749010477188016928003324ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value=''), IntProgress(value=0, bar_style='success')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lease radhofanazizi_gmail_com-power-management has reached status active\n"
     ]
    }
   ],
   "source": [
    "from chi import lease\n",
    "from datetime import timedelta\n",
    "import os\n",
    "\n",
    "my_lease = lease.Lease(f\"{os.getenv('USER')}-power-management\", duration=timedelta(hours=3))\n",
    "my_lease.add_node_reservation(nodes=[available_nodes[0]]) # or you could use node_type=node_type\n",
    "my_lease.add_fip_reservation(1) # include a floating ip\n",
    "my_lease.submit(idempotent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a server on the node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for server radhofanazizi_gmail_com-power-management's status to become ACTIVE. This typically takes 10 minutes, but can take up to 20 minutes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3430c5e4e0443e0966913c158fe58da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value=''), IntProgress(value=0, bar_style='success')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server has moved to status ACTIVE\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style='border-collapse: collapse; width: 100%;'><tr style='background-color: #f2f2f2;'><th style='border: 1px solid #ddd; padding: 8px;'>Attribute</th><th style='border: 1px solid #ddd; padding: 8px;'>radhofanazizi_gmail_com-power-management</th></tr><tr><td style='border: 1px solid #ddd; padding: 8px;'>Id</td><td style='border: 1px solid #ddd; padding: 8px;'>586f9dbc-89fb-4254-87f8-a6d21141be6f</td></tr><tr><td style='border: 1px solid #ddd; padding: 8px;'>Status</td><td style='border: 1px solid #ddd; padding: 8px;'>ACTIVE</td></tr><tr><td style='border: 1px solid #ddd; padding: 8px;'>Image Name</td><td style='border: 1px solid #ddd; padding: 8px;'>CC-Ubuntu22.04</td></tr><tr><td style='border: 1px solid #ddd; padding: 8px;'>Flavor Name</td><td style='border: 1px solid #ddd; padding: 8px;'>baremetal</td></tr><tr><td style='border: 1px solid #ddd; padding: 8px;'>Addresses</td><td style='border: 1px solid #ddd; padding: 8px;'><strong>sharednet1:</strong><br>&nbsp;&nbsp;IP: 10.52.2.187 (v4)<br>&nbsp;&nbsp;Type: fixed<br>&nbsp;&nbsp;MAC: bc:97:e1:78:f1:a0<br></td></tr><tr><td style='border: 1px solid #ddd; padding: 8px;'>Network Name</td><td style='border: 1px solid #ddd; padding: 8px;'>sharednet1</td></tr><tr><td style='border: 1px solid #ddd; padding: 8px;'>Created At</td><td style='border: 1px solid #ddd; padding: 8px;'>2025-03-26T14:17:16Z</td></tr><tr><td style='border: 1px solid #ddd; padding: 8px;'>Keypair</td><td style='border: 1px solid #ddd; padding: 8px;'>trovi-e18da17</td></tr><tr><td style='border: 1px solid #ddd; padding: 8px;'>Reservation Id</td><td style='border: 1px solid #ddd; padding: 8px;'>c049c37d-c414-4833-a885-31b28cc9ffbd</td></tr><tr><td style='border: 1px solid #ddd; padding: 8px;'>Host Id</td><td style='border: 1px solid #ddd; padding: 8px;'>b281b13a05d4a4d342f673906de4005142c2819a049809e34ac97306</td></tr><tr><td style='border: 1px solid #ddd; padding: 8px;'>Host Status</td><td style='border: 1px solid #ddd; padding: 8px;'>None</td></tr><tr><td style='border: 1px solid #ddd; padding: 8px;'>Hypervisor Hostname</td><td style='border: 1px solid #ddd; padding: 8px;'>021d8369-10e4-429c-9df4-cc4eb86216ee</td></tr><tr><td style='border: 1px solid #ddd; padding: 8px;'>Is Locked</td><td style='border: 1px solid #ddd; padding: 8px;'>False</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from chi import server\n",
    "\n",
    "my_server = server.Server(\n",
    "    f\"{os.getenv('USER')}-power-management\",\n",
    "    reservation_id=my_lease.node_reservations[0][\"id\"],\n",
    "    image_name=\"CC-Ubuntu22.04\", # or use image_name\n",
    ")\n",
    "my_server.submit(idempotent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure networking on the node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking connectivity to 129.114.109.67 port 22.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "301fb67f752a416699af365a23734a89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value=''), IntProgress(value=0, bar_style='success')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful\n"
     ]
    }
   ],
   "source": [
    "fip = my_lease.get_reserved_floating_ips()[0]\n",
    "my_server.associate_floating_ip(fip)\n",
    "my_server.check_connectivity(host=fip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Fairify\n",
    "\n",
    "Now, we can finally run Fairify. First we need to clone the github repo first and then run the reprduce.sh script which contain the instructions from README.md\n",
    "packaged into a bash file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'Fairify'...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Result cmd='rm -rf Fairify && git clone https://github.com/radhofan/Fairify.git' exited=0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_server.execute(\"rm -rf Fairify && git clone https://github.com/radhofan/Fairify.git\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: File or directory already exists: '/home/cc/miniconda'\n",
      "If you want to update an existing installation, use the -u option.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - conda-forge\n",
      " - defaults\n",
      "Platform: linux-64\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "Running `shell init`, which:\n",
      " - modifies RC file: \"/home/cc/.bashrc\"\n",
      " - generates config for root prefix: \u001b[1m\"/home/cc/miniconda\"\u001b[0m\n",
      " - sets mamba executable to: \u001b[1m\"/home/cc/miniconda/bin/mamba\"\u001b[0m\n",
      "The following has been added in your \"/home/cc/.bashrc\" file\n",
      "\n",
      "# >>> mamba initialize >>>\n",
      "# !! Contents within this block are managed by 'mamba shell init' !!\n",
      "export MAMBA_EXE='/home/cc/miniconda/bin/mamba';\n",
      "export MAMBA_ROOT_PREFIX='/home/cc/miniconda';\n",
      "__mamba_setup=\"$(\"$MAMBA_EXE\" shell hook --shell bash --root-prefix \"$MAMBA_ROOT_PREFIX\" 2> /dev/null)\"\n",
      "if [ $? -eq 0 ]; then\n",
      "    eval \"$__mamba_setup\"\n",
      "else\n",
      "    alias mamba=\"$MAMBA_EXE\"  # Fallback on help from mamba activate\n",
      "fi\n",
      "unset __mamba_setup\n",
      "# <<< mamba initialize <<<\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning  libmamba 'repo.anaconda.com', a commercial channel hosted by Anaconda.com, is used.\n",
      "    \n",
      "warning  libmamba Please make sure you understand Anaconda Terms of Services.\n",
      "    \n",
      "warning  libmamba See: https://legal.anaconda.com/policies/en/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Transaction\n",
      "\n",
      "  Prefix: /home/cc/miniconda/envs/fairify\n",
      "\n",
      "  Updating specs:\n",
      "\n",
      "   - python=3.9\n",
      "\n",
      "\n",
      "  Package               Version  Build           Channel         Size\n",
      "───────────────────────────────────────────────────────────────────────\n",
      "  Install:\n",
      "───────────────────────────────────────────────────────────────────────\n",
      "\n",
      "  + _libgcc_mutex           0.1  main            pkgs/main     Cached\n",
      "  + _openmp_mutex           5.1  1_gnu           pkgs/main     Cached\n",
      "  + ca-certificates   2025.2.25  h06a4308_0      pkgs/main     Cached\n",
      "  + ld_impl_linux-64       2.40  h12ee557_0      pkgs/main     Cached\n",
      "  + libffi                3.4.4  h6a678d5_1      pkgs/main     Cached\n",
      "  + libgcc-ng            11.2.0  h1234567_1      pkgs/main     Cached\n",
      "  + libgomp              11.2.0  h1234567_1      pkgs/main     Cached\n",
      "  + libstdcxx-ng         11.2.0  h1234567_1      pkgs/main     Cached\n",
      "  + ncurses                 6.4  h6a678d5_0      pkgs/main     Cached\n",
      "  + openssl              3.0.16  h5eee18b_0      pkgs/main     Cached\n",
      "  + pip                    25.0  py39h06a4308_0  pkgs/main     Cached\n",
      "  + python               3.9.21  he870216_1      pkgs/main     Cached\n",
      "  + readline                8.2  h5eee18b_0      pkgs/main     Cached\n",
      "  + setuptools           75.8.0  py39h06a4308_0  pkgs/main     Cached\n",
      "  + sqlite               3.45.3  h5eee18b_0      pkgs/main     Cached\n",
      "  + tk                   8.6.14  h39e8969_0      pkgs/main     Cached\n",
      "  + tzdata                2025a  h04d1e81_0      pkgs/main     Cached\n",
      "  + wheel                0.45.1  py39h06a4308_0  pkgs/main     Cached\n",
      "  + xz                    5.6.4  h5eee18b_1      pkgs/main     Cached\n",
      "  + zlib                 1.2.13  h5eee18b_1      pkgs/main     Cached\n",
      "\n",
      "  Summary:\n",
      "\n",
      "  Install: 20 packages\n",
      "\n",
      "  Total download: 0 B\n",
      "\n",
      "───────────────────────────────────────────────────────────────────────\n",
      "\n",
      "\n",
      "\n",
      "Transaction starting\n",
      "Linking _libgcc_mutex-0.1-main\n",
      "Linking ld_impl_linux-64-2.40-h12ee557_0\n",
      "Linking libstdcxx-ng-11.2.0-h1234567_1\n",
      "Linking ca-certificates-2025.2.25-h06a4308_0\n",
      "Linking libgomp-11.2.0-h1234567_1\n",
      "Linking _openmp_mutex-5.1-1_gnu\n",
      "Linking libgcc-ng-11.2.0-h1234567_1\n",
      "Linking xz-5.6.4-h5eee18b_1\n",
      "Linking openssl-3.0.16-h5eee18b_0\n",
      "Linking libffi-3.4.4-h6a678d5_1\n",
      "Linking zlib-1.2.13-h5eee18b_1\n",
      "Linking ncurses-6.4-h6a678d5_0\n",
      "Linking tk-8.6.14-h39e8969_0\n",
      "Linking readline-8.2-h5eee18b_0\n",
      "Linking sqlite-3.45.3-h5eee18b_0\n",
      "Linking tzdata-2025a-h04d1e81_0\n",
      "Linking python-3.9.21-he870216_1\n",
      "Linking wheel-0.45.1-py39h06a4308_0\n",
      "Linking setuptools-75.8.0-py39h06a4308_0\n",
      "Linking pip-25.0-py39h06a4308_0\n",
      "\n",
      "Transaction finished\n",
      "\n",
      "\n",
      "To activate this environment, use:\n",
      "\n",
      "    mamba activate fairify\n",
      "\n",
      "Or to execute a single command in this environment, use:\n",
      "\n",
      "    mamba run -n fairify mycommand\n",
      "\n",
      "Collecting z3-solver (from -r Fairify/requirements.txt (line 1))\n",
      "  Using cached z3_solver-4.14.1.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (602 bytes)\n",
      "Collecting tensorflow==2.5.0 (from -r Fairify/requirements.txt (line 2))\n",
      "  Using cached tensorflow-2.5.0-cp39-cp39-manylinux2010_x86_64.whl.metadata (2.8 kB)\n",
      "Collecting aif360 (from -r Fairify/requirements.txt (line 3))\n",
      "  Using cached aif360-0.6.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting numpy~=1.19.2 (from tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached numpy-1.19.5-cp39-cp39-manylinux2010_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting absl-py~=0.10 (from tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached absl_py-0.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting astunparse~=1.6.3 (from tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers~=1.12.0 (from tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached flatbuffers-1.12-py2.py3-none-any.whl.metadata (872 bytes)\n",
      "Collecting google-pasta~=0.2 (from tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py~=3.1.0 (from tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached h5py-3.1.0-cp39-cp39-manylinux1_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting keras-preprocessing~=1.1.2 (from tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opt-einsum~=3.3.0 (from tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting protobuf>=3.9.2 (from tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached protobuf-6.30.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Collecting six~=1.15.0 (from tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached six-1.15.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting termcolor~=1.1.0 (from tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached termcolor-1.1.0-py3-none-any.whl\n",
      "Collecting typing-extensions~=3.7.4 (from tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached typing_extensions-3.7.4.3-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: wheel~=0.35 in ./miniconda/envs/fairify/lib/python3.9/site-packages (from tensorflow==2.5.0->-r Fairify/requirements.txt (line 2)) (0.45.1)\n",
      "Collecting wrapt~=1.12.1 (from tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached wrapt-1.12.1-cp39-cp39-linux_x86_64.whl\n",
      "Collecting gast==0.4.0 (from tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting tensorboard~=2.5 (from tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting tensorflow-estimator<2.6.0,>=2.5.0rc0 (from tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached tensorflow_estimator-2.5.0-py2.py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting keras-nightly~=2.5.0.dev (from tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting grpcio~=1.34.0 (from tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached grpcio-1.34.1-cp39-cp39-manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting scipy>=1.2.0 (from aif360->-r Fairify/requirements.txt (line 3))\n",
      "  Using cached scipy-1.13.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Collecting pandas>=0.24.0 (from aif360->-r Fairify/requirements.txt (line 3))\n",
      "  Using cached pandas-2.2.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Collecting scikit-learn>=1.0 (from aif360->-r Fairify/requirements.txt (line 3))\n",
      "  Using cached scikit_learn-1.6.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting matplotlib (from aif360->-r Fairify/requirements.txt (line 3))\n",
      "  Using cached matplotlib-3.9.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "INFO: pip is looking at multiple versions of pandas to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pandas>=0.24.0 (from aif360->-r Fairify/requirements.txt (line 3))\n",
      "  Using cached pandas-2.2.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "  Using cached pandas-2.2.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "  Using cached pandas-2.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "  Using cached pandas-2.1.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "  Using cached pandas-2.1.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "  Using cached pandas-2.1.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "  Using cached pandas-2.1.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "INFO: pip is still looking at multiple versions of pandas to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached pandas-2.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "  Using cached pandas-2.0.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting python-dateutil>=2.8.2 (from pandas>=0.24.0->aif360->-r Fairify/requirements.txt (line 3))\n",
      "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting pytz>=2020.1 (from pandas>=0.24.0->aif360->-r Fairify/requirements.txt (line 3))\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.1 (from pandas>=0.24.0->aif360->-r Fairify/requirements.txt (line 3))\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting pandas>=0.24.0 (from aif360->-r Fairify/requirements.txt (line 3))\n",
      "  Using cached pandas-2.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "  Using cached pandas-2.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "  Using cached pandas-2.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached pandas-1.5.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "  Using cached pandas-1.5.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "  Using cached pandas-1.5.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "  Using cached pandas-1.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "  Using cached pandas-1.4.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn>=1.0->aif360->-r Fairify/requirements.txt (line 3))\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn>=1.0->aif360->-r Fairify/requirements.txt (line 3))\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "INFO: pip is looking at multiple versions of scipy to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting scipy>=1.2.0 (from aif360->-r Fairify/requirements.txt (line 3))\n",
      "  Using cached scipy-1.13.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "  Using cached scipy-1.12.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "  Using cached scipy-1.11.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "  Using cached scipy-1.11.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "  Using cached scipy-1.11.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (59 kB)\n",
      "  Using cached scipy-1.11.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (59 kB)\n",
      "  Using cached scipy-1.10.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
      "INFO: pip is looking at multiple versions of tensorboard to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tensorboard~=2.5 (from tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "  Using cached tensorboard-2.17.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "  Using cached tensorboard-2.17.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "  Using cached tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "  Using cached tensorboard-2.16.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "  Using cached tensorboard-2.16.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "  Using cached tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "INFO: pip is still looking at multiple versions of tensorboard to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached tensorboard-2.15.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "  Using cached tensorboard-2.15.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "  Using cached tensorboard-2.14.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "  Using cached tensorboard-2.14.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "  Using cached tensorboard-2.13.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached tensorboard-2.12.3-py3-none-any.whl.metadata (1.8 kB)\n",
      "  Using cached tensorboard-2.12.2-py3-none-any.whl.metadata (1.8 kB)\n",
      "  Using cached tensorboard-2.12.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "  Using cached tensorboard-2.12.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "  Using cached tensorboard-2.11.2-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard~=2.5->tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached google_auth-2.38.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard~=2.5->tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.5->tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting protobuf>=3.9.2 (from tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached protobuf-3.20.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (679 bytes)\n",
      "Collecting requests<3,>=2.21.0 (from tensorboard~=2.5->tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in ./miniconda/envs/fairify/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow==2.5.0->-r Fairify/requirements.txt (line 2)) (75.8.0)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard~=2.5->tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0 (from tensorboard~=2.5->tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl.metadata (873 bytes)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.5->tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib->aif360->-r Fairify/requirements.txt (line 3))\n",
      "  Using cached contourpy-1.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib->aif360->-r Fairify/requirements.txt (line 3))\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib->aif360->-r Fairify/requirements.txt (line 3))\n",
      "  Using cached fonttools-4.56.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (101 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib->aif360->-r Fairify/requirements.txt (line 3))\n",
      "  Using cached kiwisolver-1.4.7-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.3 kB)\n",
      "INFO: pip is looking at multiple versions of matplotlib to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting matplotlib (from aif360->-r Fairify/requirements.txt (line 3))\n",
      "  Using cached matplotlib-3.9.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "  Using cached matplotlib-3.9.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "  Using cached matplotlib-3.9.1.post1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "  Using cached matplotlib-3.9.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "  Using cached matplotlib-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "  Using cached matplotlib-3.8.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "  Using cached matplotlib-3.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "INFO: pip is still looking at multiple versions of matplotlib to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached matplotlib-3.8.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "  Using cached matplotlib-3.8.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "  Using cached matplotlib-3.7.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\n",
      "  Using cached matplotlib-3.7.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\n",
      "  Using cached matplotlib-3.7.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached matplotlib-3.7.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "  Using cached matplotlib-3.7.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "  Using cached matplotlib-3.7.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "  Using cached matplotlib-3.6.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting packaging>=20.0 (from matplotlib->aif360->-r Fairify/requirements.txt (line 3))\n",
      "  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting pillow>=6.2.0 (from matplotlib->aif360->-r Fairify/requirements.txt (line 3))\n",
      "  Using cached pillow-11.1.0-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
      "Collecting pyparsing>=2.2.1 (from matplotlib->aif360->-r Fairify/requirements.txt (line 3))\n",
      "  Using cached pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "INFO: pip is looking at multiple versions of contourpy to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting contourpy>=1.0.1 (from matplotlib->aif360->-r Fairify/requirements.txt (line 3))\n",
      "  Using cached contourpy-1.2.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "  Using cached contourpy-1.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "  Using cached contourpy-1.1.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.9 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting importlib-metadata>=4.4 (from markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached importlib_metadata-8.6.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached charset_normalizer-3.4.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard~=2.5->tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached MarkupSafe-3.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting zipp>=3.20 (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.0->-r Fairify/requirements.txt (line 2))\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Using cached tensorflow-2.5.0-cp39-cp39-manylinux2010_x86_64.whl (454.4 MB)\n",
      "Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Using cached z3_solver-4.14.1.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.5 MB)\n",
      "Using cached aif360-0.6.1-py3-none-any.whl (259 kB)\n",
      "Using cached absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Using cached grpcio-1.34.1-cp39-cp39-manylinux2014_x86_64.whl (4.0 MB)\n",
      "Using cached h5py-3.1.0-cp39-cp39-manylinux1_x86_64.whl (4.4 MB)\n",
      "Using cached keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)\n",
      "Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Using cached numpy-1.19.5-cp39-cp39-manylinux2010_x86_64.whl (14.9 MB)\n",
      "Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Using cached pandas-1.4.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
      "Using cached scikit_learn-1.6.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
      "Using cached scipy-1.10.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
      "Using cached six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Using cached tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
      "Using cached protobuf-3.20.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "Using cached tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n",
      "Using cached typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Using cached matplotlib-3.6.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.8 MB)\n",
      "Using cached contourpy-1.1.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.56.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "Using cached google_auth-2.38.0-py2.py3-none-any.whl (210 kB)\n",
      "Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached kiwisolver-1.4.7-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "Using cached Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Using cached pillow-11.1.0-cp39-cp39-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "Using cached pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Using cached cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Using cached charset_normalizer-3.4.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (146 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached importlib_metadata-8.6.1-py3-none-any.whl (26 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20 kB)\n",
      "Using cached pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Using cached zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
      "Installing collected packages: z3-solver, wrapt, typing-extensions, termcolor, tensorflow-estimator, tensorboard-plugin-wit, pytz, keras-nightly, flatbuffers, zipp, urllib3, threadpoolctl, tensorboard-data-server, six, pyparsing, pyasn1, protobuf, pillow, packaging, oauthlib, numpy, MarkupSafe, kiwisolver, joblib, idna, gast, fonttools, cycler, charset-normalizer, certifi, cachetools, werkzeug, scipy, rsa, requests, python-dateutil, pyasn1-modules, opt-einsum, keras-preprocessing, importlib-metadata, h5py, grpcio, google-pasta, contourpy, astunparse, absl-py, scikit-learn, requests-oauthlib, pandas, matplotlib, markdown, google-auth, google-auth-oauthlib, aif360, tensorboard, tensorflow\n",
      "Successfully installed MarkupSafe-3.0.2 absl-py-0.15.0 aif360-0.6.1 astunparse-1.6.3 cachetools-5.5.2 certifi-2025.1.31 charset-normalizer-3.4.1 contourpy-1.1.1 cycler-0.12.1 flatbuffers-1.12 fonttools-4.56.0 gast-0.4.0 google-auth-2.38.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.34.1 h5py-3.1.0 idna-3.10 importlib-metadata-8.6.1 joblib-1.4.2 keras-nightly-2.5.0.dev2021032900 keras-preprocessing-1.1.2 kiwisolver-1.4.7 markdown-3.7 matplotlib-3.6.3 numpy-1.19.5 oauthlib-3.2.2 opt-einsum-3.3.0 packaging-24.2 pandas-1.4.4 pillow-11.1.0 protobuf-3.20.3 pyasn1-0.6.1 pyasn1-modules-0.4.1 pyparsing-3.2.3 python-dateutil-2.9.0.post0 pytz-2025.2 requests-2.32.3 requests-oauthlib-2.0.0 rsa-4.9 scikit-learn-1.6.1 scipy-1.10.1 six-1.15.0 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.5.0 tensorflow-estimator-2.5.0 termcolor-1.1.0 threadpoolctl-3.6.0 typing-extensions-3.7.4.3 urllib3-2.3.0 werkzeug-3.1.3 wrapt-1.12.1 z3-solver-4.14.1.0 zipp-3.21.0\n",
      "Started running verification for Fairify/src/AC/Verify-AC.py models.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-26 15:51:36.822544: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2025-03-26 15:51:36.822565: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2025-03-26 15:51:38.304002: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2025-03-26 15:51:38.304022: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2025-03-26 15:51:38.304039: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (radhofanazizi-gmail-com-power-management): /proc/driver/nvidia/version does not exist\n",
      "2025-03-26 15:51:38.304220: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "my_server.execute(\"chmod +x Fairify/reproduce.sh\")\n",
    "my_server.execute(\"bash Fairify/reproduce.sh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
